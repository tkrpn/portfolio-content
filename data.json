{
    "general": {
        "description": "Solving complex problems on a conceptual level and operationalizing them purposefully is my strength. I like to work creatively, involved and iteratively in a team or focus on my own projects in a goal-oriented and independent way. I love and live IT and like to surround myself with like-minded people or people who are similarly enthusiastic about their area of expertise.",
        "facts": [
            "-3.5- years of relevant work experience for 3 employers (~7 years in total).",
            "-8- consulting projects for 5 clients in 4 industries.",
            "-14- publications, 2 of which for academia, 6 for practice & 6 public speeches.",
            "Proficient in -5- programming languages and 3 subject areas.",
            "-1.2- GPA B.Sc. and finished top of the year, 1.2 GPA M.Sc. at TUM."
        ],
        "status":"Currently, I am pursuing my master's degree at TUM and spending a semester abroad at DTU in Copenhagen. I love technology and code, especially ML, DL and AI and lately also Web3 and smart contract development in Solidity. Furthermore, i have experience in management consulting and research. For more, feel free to check out my LinkedIn.",
        "headers": {
            "consulting": "In my approximately 3.5 years in various consulting positions I was able to gain valuable experience in IT, management and strategy consulting. My focus was especially on data, analytics and AI strategy. In the following you will find some of the projects I have been heavily involved in. Please note that all information that could point to clients has been removed.",
            "academia": "Various research and consulting projects have resulted in publications for academic and practical audiences. In addition, I have had the opportunity to give several public presentations at conferences and events on topics such as ERP, IoT, Analytics and Data Science. If you would like to have more information about the individual publications or would like to receive documents or presentations, please feel free to contact me."
        },
        "contact": [
            {"title": "LinkedIn", "description": "For more information about my career please have a look at LinkedIn. I look forward to your networking request!", "link":"https://www.linkedin.com/in/tim-körppen/"},
            {"title": "ResearchGate", "description": "My publications are also on ResearchGate. Check them out and let's connect.", "link":"https://www.researchgate.net/profile/Tim-Koerppen"},
            {"title": "GitHub", "description": "You can also find some of my projects on GitHub. Check them out!", "link":"https://github.com/tkrpn"},
            {"title": "E-Mail", "description": "I am also always glad to receive an e-mail from you. Also feedback about this site (and bugs if you found any) are always welcome. :)", "link":"mailto:ws.tim.krpn@gmail.com"}
        ]
    },
    "chonology": {
        "academic": [
            {"title": "B.Sc. Information Systems"},
            {"title": "M.Sc. Information Systems"}
        ],
        "professional": [
            {"title": "Consultant"}
        ]
    },
    "portfolio": {
        "projects": [
            {"id": 1, "title": "Algorithmic trading research and backtesting", "year": "2019",  "ldescription": "The goal of this project was to use machine learning to identify patterns in stock prices in order to be able to use these models for predictions and automated buy and sell decisions. For this purpose, a backtesting environment was designed and implemented to enable the testing of models on the basis of historical price developments. \nThe primary focus, however, was the exploration of possible models, ranging from simple models based on moving averages of different time frames to more complex regressors, classifiers and neural networks (especially RNNs and CNNs). \n Complementary to this, a semtiment classifier for stock-related newspaper headlines was created in a group project, which also merged into a university project. This ensemble of models for the technical analysis of price trends and the sentiment classifier of the headlines was intended to become the basis for automated trading. \nThe screenshots show the backtesting tool created in Python and PyQt for this purpose (including portfolio and stock simulation and plotting). This contains various settings (especially the model to be tested) for configuring the simulation as well as output screens for the overview of the purchases/sales, the own capital and the stock holdings over the course of the simulation. Furthermore, the screenshots show the architectural concept of the backtesting tool, sections of the exploration of different models and evaluation outputs of the sentiment models.", "mlang": "Python", "tech": ["NumPy", "Pandas", "Matplotlib", "PyQt", "Scikit-learn", "Tensorflow"], "img": ["algotrade_1.jpeg", "algotrade_2.jpeg", "algotrade_3.jpeg", "algotrade_4.jpeg", "algotrade_5.jpeg", "algotrade_6.jpeg", "algotrade_7.jpeg", "algotrade_8.jpeg", "algotrade_9.jpeg"] },
            {"id": 2, "title": "AR digital twin for IIoT", "year": "2019",  "ldescription": "The Research and Application Center Industry 4.0 at the University of Potsdam simulates, among other things, a scenario for the production of an artificial knee joint, also known as a femur, in which various successive production stages are run through. These production stages are mapped to physical changes in the cyber-physical simulation environment of the Research and Application Center 4.0, to which the user must react and follow predefined work steps. \nThe goal of the project was the conception and prototypical implementation of an augmented reality application that displays a virtual 3D model of the femur as well as the individual production stages. These models, supplemented by additional production information, are to be displayed dynamically during the simulation run, i.e. depending on the production progress. \nThe application was built in Unity3D and uses Vuforia as the AR engine. The app was deployed on an Android tablet and AR-Glasses (Epson). The client-server communication is based on a websocket connection so that any number of devices can be active at the same time and have access to the live data of the cyber-physical environment.", "mlang": "C#", "tech": ["Unity3D", "Vuforia"], "img": ["ar_digital_twin_1.jpeg", "ar_digital_twin_2.jpeg", "ar_digital_twin_3.jpeg", "ar_digital_twin_4.jpeg"] },
            {"id": 3, "title": "Cash register and warehouse management system", "year": "2020",  "ldescription": "In this university group project (software engineering course, 3rd bachelor semester, 4 persons per group) a client application based on Java and Swing was created. This application simulates a cash register and warehouse management system.\nOn the one hand it is possible to perform a checkout process where several products are registered by EAN/PLU number and then an invoice is issued including the amount to be paid. On the other hand, the merchandise management component offers the possibility to modify the individual database entries of the products, to add new products or to delete them.", "mlang": "Java", "tech": ["Swing"], "img": ["cashregister_1.jpeg", "cashregister_2.jpeg"] },
            {"id": 4, "title": "Web crawling", "year": "2020",  "ldescription": "In the course of time, various web crawlers were created for different projects. Mostly BeautifulSoup was used if the HTML source code had to be requested statically or the target page was not generated dynamically via JavaScript or user input was necessary. For target pages that were dynamically generated, had special defense mechanisms (e.g. captchas or movement patterns) or if user input was required (e.g. logins or content scrolling), headless web browsers (chromedriver) and selenium were used.\nThis toolset was used for the following projects:\n1) Collection of public information about subjects in an academic context (based on search engine queries that were the starting point for the crawling of the retrieved pages, which were then searched using RegEx). \n2) Collection of text fragments from an online legal forum (a total of 50,000 forum threads) as well as the associated forum categories as a training dataset for the training of an ML classifier.\n3) Collection of accommodation listings in order to be able to homogenize, analyze and visualize them afterwards.\nAll crawling activities were always done ethically and lawfully", "mlang": "Python", "tech": ["BeautifulSoup", "Selenium", "NumPy", "Pandas", "Matplotlib"], "img": ["accomm_3.jpeg", "accomm_2.jpeg"] },
            {"id": 5, "title": "Legal Tech Chatbot & Matching Platform", "year": "2021",  "ldescription": "The legal-tech platform (project name 'JurAI') aimed to digitize parts of the legal advice process in order to provide consumers with easier access to legal assistance and to facilitate the automation of repetitive processes for lawyers.\nFor this purpose, a platform was designed that consists of several modules: \n1) A chat-bot that can understand, classify, extract information and process legal problems.\n2) Different nlp models (for classification of legal problems, extraction of information and conversation).\n3) A high dimensional graph database that stores relationships between legal texts.\n4) A platform on which clients and lawyers can interact.\nThe conversation component of the chatbot is based on intent-based context recognition and guides the flow of conversation using a state-machine. For classification and information extraction, real legal cases were collected (see webcrawling project) and different machine learning (esp. SVC and Random Forest) and deep learning models (esp. RNN/LSTM) were trained (on Microsoft Azure).\nThe graph database was based on various python libraries (e.g. NetworkX) and own adjacency data structures in early stages. A migration to Neo4J is planned.", "mlang": "Python", "tech": ["Django", "NumPy", "Pandas", "Tensorflow", "Scikit-learn", "Matplotlib", "jQuery", "Ajax"], "img": ["jur_1.jpeg", "jur_2.jpeg", "jur_3.jpeg", "jur_4.jpeg"] },
            {"id": 6, "title": "Shipping management and IoT mailbox system", "year": "2022",  "ldescription": "ASEDelivery offers a smart solution for sending and receiving parcels with the help of parcel boxes that can be loaded by the deliverer and retrieved by the recipient using an RFID chip.Furthermore, shipments can be managed and assigned to different deliverers by means of corresponding views. Deliverers and customers also have their own views to track their shipments.\nFor this purpose, a scalable, containerized solution based on Java Spring Boot was developed in a service-oriented architecture (SOA) in a university project (1st master semester, 5 students). Furthermore, appropriate load balancing via a gateway was ensured and a service registry (eureka) was implemented. While the individual backend micro services were implemented in spring boot and linked to a MongoDB, the frontend was based on React.\nThe packet boxes were simulated using a raspberry pi and featured LEDs for status indication (esp. access allowed and denied) as well as an RFID reader.\nThe containers were built using automated GitLab CI/CD pipelines and deployed to Azure.", "mlang": "Java", "tech": ["React.JS", "Spring Boot", "Azure", "Redux", "Maven", "MongoDB"], "img": ["delivery_1.jpeg", "delivery_2.jpeg", "delivery_3.jpeg", "delivery_4.jpeg", "delivery_5.jpeg", "delivery_6.jpeg", "delivery_7.jpeg", "delivery_8.jpeg", "delivery_9.jpeg", "delivery_10.jpeg", "delivery_11.jpeg", "delivery_12.jpeg", "delivery_13.jpeg"] },
            {"id": 7, "title": "EV charging and fleet management system", "year": "2022",  "ldescription": "In cooperation with E.ON and Munich Airport, a real-world problem of Munich Airport was worked on as part of the TechChallenge of UnternehmerTUM. Specifically, a solution was to be found to make the EV charging situation at Munich Airport simpler, more transparent and more efficient.\nFor this purpose, several interviews with employees of the Munich airport were conducted to understand the problem and to collect requirements. Furthermore, conceptions, mockups and business cases were created and the implementation was carried out.\nFor the implementation the Django web framework was used and supplemented with Bootstrap UI. The data management for the prototype was implemented only with SQLite. The app was deployed in Azure Web Services and was available to the public for some time.\nThe implementation was done entirely by myself, as my team members had no prior technical knowledge.\nThe project won the competition against three other teams that implemented the same project for E.ON and Munich Airport.", "mlang": "Python", "tech": ["Django", "SQLite", "Bootstrap", "Azure"], "img": ["intellicharge_1.jpeg", "intellicharge_2.jpeg", "intellicharge_3.jpeg", "intellicharge_4.jpeg", "intellicharge_5.jpeg", "intellicharge_6.jpeg", "intellicharge_7.jpeg", "intellicharge_8.jpeg", "intellicharge_9.jpeg"] },
            {"id": 8, "title": "Accommodation matching platform", "year": "2022",  "ldescription": "AccoMM aims to simplify the search for apartments or shared apartments for both apartment seekers and housing providers. For this purpose, the users are shown offers (advertisements or interested candidates) that are perfectly tailored to their interests and through which they can comfortably swipe. If a match arises, the parties concerned can chat with each other directly on the platform. In addition, the platform offers a store where boosts or memberships can be purchased in order to receive advantages when using the platform.\nThe platform is based on the MERN stack (MongoDB, Express, React, Node.Js) and was developed in a university project (2nd master semester, 3 students). The chat is based on a Socket.io websocket implementation and allows real-time chatting. The notification system is also based on websocket connections. Furthermore the Stripe-API was used as payment provider to enable payments in the store.\nWithin the scope of this project, various presentations on the business model and conceptual preparation for implementation were also made.", "mlang": "JavaScript", "tech": ["React.JS", "Node.JS", "Express", "MongoDB"], "img": ["accomm_1.jpeg", "accomm_2.jpeg", "accomm_3.jpeg", "accomm_4.jpeg", "accomm_5.jpeg", "accomm_6.jpeg", "accomm_7.jpeg", "accomm_8.jpeg", "accomm_9.jpeg", "accomm_10.jpeg", "accomm_11.jpeg", "accomm_12.jpeg"], "material": [{"text": ""}, {"text": ""}] },
            {"id": 9, "title": "ERC20 and Web3 development", "year": "2022",  "ldescription": "In this university project, smart contracts for a custom ERC20 token and a bank smart contract (to borrow and deposit tokens and pay fees and receive interest) were written. In addition, an oracle was created to obtain conversion rates for calculating interest.\nThese smart contracts were deployed on different test nets (locally on truffle and ganache and remotely on Rinkeby Ethereum net). MetaMask and the currency commonly used on Rinkeby (ETH) were used for this purpose.", "mlang": "Solidity", "tech": ["OpenZeppelin", "Truffle", "Ganache", "Infura", "Rinkeby"], "img": ["token_1.jpeg", "token_2.jpeg", "token_3.jpeg", "token_4.jpeg", "token_5.jpeg"] },
            {"id": 10, "title": "Portfolio page", "year": "2022",  "ldescription": "The portfolio page is entirely based on React to enable deployment without a backend server on GitHub pages. This involved experimenting with different features of React (especially the different hooks), JavaScript, HTML5 and CSS. In particular, the project slider of the main page was programmed from scratch, which required some experiments (especially between a JS- or CSS-based implementation of the animation). \nSince no backend server is used that could communicate with a database, but still a later extensibility with new content should be enabled without redeployment, the data storage is based on JSON communication with an external cloud hosting provider (simulates API server).", "mlang": "JavaScript", "tech": ["React.JS", "GitHub-Pages"], "img": ["portfolio_1.jpeg", "portfolio_2.jpeg", "portfolio_3.jpeg", "portfolio_4.jpeg", "portfolio_5.jpeg", "portfolio_6.jpeg", "portfolio_7.jpeg"] },
            {"id": 11, "title": "In-depth courses and exercises on ML, DL and AI", "year": "2022",  "ldescription": "Implementation of many problems in courses on Machine Learning (1 & 2) and Deep Learning as well as Artificial Intelligence (4 courses in total, 23 ECTS). Manual implementation of many algorithms (e.g. random forests, core SVMs, simple neural networks, Bayesian models) and use of common libraries (esp. scikit-learn, Tensorflow/Keras and PyTorch). Experience with handling a wide variety of test datasets (e.g. MNIST, Fashion-MNIST, Iris, MovieLens, Cifar10, MSRC-v2 segmentation, IMDb Sentiment, CommonRoad).\nOverall, the theory and practice of (among others) the following methods were learned and practiced:\n- Basic supervised & unsupervised models (e.g. linear regressions, logistic regressions, decision trees, random forests)\n- More advanced models (e.g. SVMs, bayesian models, kernalized models)\n- Graphical models & inference\n- Recommender engines (e.g. content-based, per user models, collaborative filtering, latent features & matrix factorization)\n- Reinforcement learning methods (e.g. markov decision processes, monte-carlo sampling, Q-learning, monte-carlo tree search, policy gradient)\n- Simple neural networks (for regression, binary and multi-class classification)\n- Advanced neural networks (CNNs, U-Net, LSTMs & RNNs, transfer learning, auto encoders, GANs)\n- Feature selection and augmentation (e.g. PCA, TSNE, auto encoders)\n- Hyperparameter tuning and optimization\n- More non-ML based methods (e.g. informed & uninformed search, constraint satisfaction problems, first order logic, bayesian networks, HMMs)\nThe screenshots show some parts of these implementations, but are limited to visuals.", "mlang": "Python", "tech": ["Scikit-learn", "Tensorflow", "PyTorch", "Colab", "NumPy", "Pandas", "Matplotlib"], "img": ["ml_1.jpeg", "ml_2.jpeg", "ml_3.jpeg", "ml_4.jpeg", "ml_5.jpeg", "ml_6.jpeg", "ml_7.jpeg", "ml_8.jpeg", "ml_9.jpeg", "ml_10.jpeg"] }
        ],
        "publications": [
            {"id": 1, "title": "A proposal for future data organization in enterprise systems—an analysis of established database approaches", "outlet": "Information Systems and e-Business Management", "date":"5/2022", "type":"Paper", "authors":"Bender, B., Bertheau , C., Körppen, T., Lauppe, H., Gronau, N.", "img":"paper_future_dbs.jpeg", "doi":"10.1007/s10257-022-00555-6", "rg":"https://www.researchgate.net/publication/360373755_A_proposal_for_future_data_organization_in_enterprise_systems-an_analysis_of_established_database_approaches", "abstract": "The digital transformation sets new requirements to all classes of enterprise systems in companies. ERP systems in particular, which represent the dominant class of enterprise systems, are struggling to meet the new requirements at all levels of the architecture. Therefore, there is an urgent need to reconsider the overall architecture of the systems and address the root of the related issues. Given that many restrictions ERP pose on their adaptability are related to the standardization of data, the database layer of ERP systems is addressed. Since database serve as the foundation for data storage and retrieval, they limit the flexibility of enterprise systems and the chance to adapt to new requirements accordingly. So far, relational databases are widely used. Using a systematic literature approach, recent requirements for ERP systems were identified. Prominent database approaches were assessed against the 23 requirements identified. The results reveal the strengths and weaknesses of recent database approaches. To this end, the results highlight the demand to combine multiple database approaches to fulfill recent business requirements. From a conceptual point of view, this paper supports the idea of federated databases which are interoperable to fulfill future requirements and support business operation. This research forms the basis for renewal of the current generation of ERP systems and proposes to ERP vendors to use different database concepts in the future."},
            {"id": 2, "title": "Development of an AI ERP Indicator - Evaluation of the Potential Exploitation of Artificial Intelligence in Enterprise Resource Planning Systems (german)", "outlet": "Whitepaper", "date":"1/2022", "type":"Paper", "authors":"Grum, M., Körppen, T., Lauppe, H., Korjahn, N., Gronau, N.", "img":"paper_ki-reifegrad.jpeg", "rg":"https://www.researchgate.net/publication/360577107_Entwicklung_eines_KI-ERP-Indikators_-_Evaluation_der_Potenzialerschliessung_von_Kunstlicher_Intelligenz_in_Enterprise-Resource-Planning-Systemen", "abstract": "Künstliche Intelligenz (KI) gewinnt in zahlreichen Branchen rasant an Bedeutung und wird zunehmend auch in Enterprise Resource Planning (ERP)-Systemen als Anwendungsbereich erschlossen. Die Idee, dass Maschinen die kognitiven Fähigkeiten des Menschen imitieren können, indem Wissen durch Lernen auf Basis von Beispielen in Daten, Informationen und Erfahrungen generiert wird, ist heute ein Schlüsselelement der digitalen Transformation. Jedoch charakterisiert der Einsatz von KI in ERP-System einen hohen Komplexitätsgrad, da die KI als Querschnittstechnologie zu verstehen ist, welche in unterschiedlichen Unternehmensbereichen zum Einsatz kommen kann. Auch die Anwendungsgrade können sich dabei erheblich voneinander unterscheiden. Um trotz dieser Komplexität den Einsatz der KI in ERP-Systemen erfassen und systembezogen vergleichen zu können, wurde im Rahmen dieser Studie ein Reifegradmodell entwickelt. Dieses bildet die Ausgangsbasis zur Ermittlung der KI-Reife in ERP-Systemen und grenzt dabei die folgenden vier KI- bzw. systembezogenen Ebenen voneinander ab: 1) Technische Möglichkeiten, 2) Datenreife, 3) Funktionsreife und 4) Erklärfähigkeit des Systems."},
            {"id": 3, "title": "Data management: Integrated instead of isolated (german)", "outlet": "Digital Business Cloud", "date":"1/2022", "type":"Paper", "authors":"Bender, B., Körppen, T. ", "img":"paper_integriert_isoliert.jpeg", "rg":"https://www.researchgate.net/publication/359619031_INTEGRIERT_STATT_ISOLIERT_-_Digital_Business_Cloud", "abstract": "Dass Daten und Analysen Innovationstreiber sind und nicht mehr nur einen Hygienefaktor darstellen, haben viele Unternehmen erkannt. Um Potenziale zu heben, müssen Daten zielführend integriert werden. Komplexe Systemlandschaften und isolierte Datenbestände erschweren dies. Technologien für die erfolgreiche Umsetzung von datengetriebenem Management müssen richtig eingesetzt werden."},
            {"id": 4, "title": "Data Warehouse, Data Lake or Data Platform - An overview of analysis-oriented data management solutions (german)", "outlet": "ERP Management", "date":"6/2021", "type":"Paper", "authors":"Körppen, T., Bender, B.", "img":"paper_dwh_dl_dp.jpeg", "rg":"https://www.researchgate.net/publication/357773722_Data_Warehouse_Data_Lake_oder_Data_Platform_-_Eine_Ubersicht_analyseorientierter_Datenhaltungslosungen", "abstract": "Die Digitalisierung des deutschen Mittelstandes schreitet weiterhin schleppend voran. So verfügt zwar ein wachsender Teil dieser Unternehmen über vereinzelte Informations- und Kommunikationssysteme, die zielführende Vernetzung und Integration dieser Systeme stellt jedoch weiterhin eine große Aufgabe dar. Besonders vor dem Hintergrund wachsender Bedürfnisse für Informationen und Transparenz sehen sich Unternehmen zunehmend mit der analyseorientierten Nutzbarmachung der Unternehmensdaten konfrontiert."},
            {"id": 5, "title": "Roles, tasks and skills of the enterprise architect in the VUCA world", "outlet": "EEE 25th International Enterprise Distributed Object Computing Workshop (EDOCW)", "date":"7/2021", "type":"Paper", "authors":"Ullrich, A., Bertheau, C., Wiedmann, M., Sultanow, E., Körppen, T., Bente, S.", "doi":"10.1109/EDOCW52865.2021.00057", "img":"paper_ea.jpeg", "rg":"https://www.researchgate.net/publication/355707075_Roles_tasks_and_skills_of_the_enterprise_architect_in_the_VUCA_world", "abstract": "For the last 20 years, enterprise architecture management (EAM) was primarily an instrument for harmonizing and consolidating IT landscapes and is lived as a transformation and governance discipline. It, however, is rather related to IT strategy than aligned to the actual corporate strategy and the work of the enterprise architect is characterized by tasks like prescribing, monitoring, documenting, and controlling. As digital transformation continues apace, companies are facing new challenges that lead to a volatile, uncertain, complex, and ambiguous (VUCA) world. To face these challenges, vision, understanding, clarity and agility allow to anticipative and implement necessary changes. This, of course, has implications for the role of the enterprise architect. S/he needs to start actively supporting innovation and taking more of an advisory role instead of just being driven by the current state of the enterprise architecture. This paper investigates the role of the enterprise architect in the VUCA world. Based on current literature and expert interviews, a survey was conducted among consultants who work as (or with) enterprise architects. Survey results include the evaluation of statements on current tasks of enterprise architects, their influence on projects and companies as well as future requirements on the roles of the enterprise architect. The results from the survey were synthesized with the findings from literature to derive the roles, tasks and skills of enterprise architect in the VUCA world."},
            {"id": 6, "title": "Insight instead of gut feeling - Transformation to a Data-Driven Organization (german)", "outlet": "Wirtschaftsinformatik und Management (Springer)", "date":"6/2021", "type":"Paper", "authors":"Körppen, T., Ullrich, A., Bertheau, C.", "doi":"10.1365/s35764-021-00370-7", "img":"paper_ddo.jpeg", "pdf":"ddo.pdf", "rg":"https://www.researchgate.net/publication/355651024_Durchblick_statt_Bauchgefuhl_-_Transformation_zur_Data-Driven_Organization", "abstract": "Um in der digitalisierten Wirtschaft mitzuspielen, müssen Unternehmen, Markt und insbesondere Kunden detailliert verstanden werden. Neben den „Big Playern“ aus dem Silicon Valley sieht der deutsche Mittelstand, der zu großen Teilen noch auf gewachsenen IT-Infrastrukturen und Prozessen agiert, oft alt aus. Um in den nächsten Jahren nicht gänzlich abgehängt zu werden, ist ein Umbruch notwendig. Sowohl Leistungserstellungsprozesse als auch Leistungsangebot müssen transparent und datenbasiert ausgerichtet werden. Nur so können Geschäftsvorfälle, das Marktgeschehen sowie Handeln der Akteure integrativ bewertet und fundierte Entscheidungen getroffen werden. In diesem Beitrag wird das Konzept der Data-Driven Organization vorgestellt und aufgezeigt, wie Unternehmen den eigenen Analyticsreifegrad ermitteln und in einem iterativen Transformationsprozess steigern können."},
            {"id": 7, "title": "Visualization of the digital twin with AR (german)", "outlet": "Fabriksoftware", "date":"4/2020", "type":"Paper", "authors":"Körppen, T., Thim, C.", "doi":"10.30844/FS20-4_19-22", "img":"paper_digitaler_zwilling.jpeg", "rg":"https://www.researchgate.net/publication/347065908_Visualisierung_des_digitalen_Zwillings_mit_AR", "abstract": "Für die Transformation der industriellen Fertigung stellt die Integration der Realwelt und die parallele Abbildung in der Digitalwelt eine wichtige Anforderung dar. Hier greift das Konzept des digitalen Zwillings zur digitalen Repräsentation physischer Objekte. Zur Verbesserung der Mensch-Maschinen-Interaktion zwischen Fabrikpersonal, Anlagen sowie Werkstücken und Steigerung der Transparenz am Shopfloor, kann ein solcher digitaler Zwilling relevante Daten liefern. In diesem Beitrag wird ein Konzept zur Visualisierung des digitalen Zwillings mittels Augmented Reality vorgestellt und evaluiert."},
            {"id": 8, "title": "Decentralized clock control in assembly (german)", "outlet": "Fabriksoftware", "date":"2/2020", "type":"Paper", "authors":"Lass, S., Körppen, T.", "doi":"10.30844/FS20-2_27-30", "img":"paper_montage.jpeg", "rg":"https://www.researchgate.net/publication/342899627_Dezentrale_Taktsteuerung_in_der_Montage", "abstract": "In der Theorie bieten dezentrale Steuerungsansätze im Produktionskontext einige Vorteile gegenüber monolithischen Zentralsystemen, die sämtliche Funktionen in einer oder wenigen Instanzen vereinen. Allerdings bedarf die praktischen Umsetzung der Anpassung des allgemeinen Konzepts der Dezentralität an die individuellen und spezifischen Anwendungsfälle insbesondere hinsichtlich ihres sinnvollen Umfangs. Ein Anwendungsfall ist die Montage von variantenreichen Produkten. Der vorliegen-de Beitrag zeigt, wie mittels der geeigneten Kombination von zentralen und dezentralen Ansätzen eine bessere Planbarkeit und Steigerung des Durchsatzes erreicht werden kann. Mit einer flexiblen Taktsteuerung der Arbeitsstationen und geeigneter Assistenz am Montagearbeitsplatz kann die bisherige werkstatt-orientierte Organisation zu einer serienähnlichen Fertigung transformiert werden. Dies geschieht unter Einsatz einer mehrschichtigen Infrastruktur, die den Industrie 4.0-Paradigmen der dezentralen Informationsverarbeitung durch autonome vernetzte Systeme folgt."},
            {"id": 9, "title": "ERP in multi-channel retailing: maximizing selection reliability and mastering implementation (german)", "outlet": "ERP Kongress Frankfurt am Main 2020", "date":"10/2019", "type":"Speech", "authors":"Körppen, T.", "img":"speech_mc.jpeg", "abstract": "This presentation started with the special requirements that a multi-channel company has for enterprise software. Subsequently, an overview of the ERP market was given and it was shown which system features multi-channel companies should pay particular attention to. Finally, a process model was presented, which companies can use to select an ERP system that is suitable for them."},
            {"id": 10, "title": "Data Driven Organization - BI as the key to success (german)", "outlet": "ERP Kongress Frankfurt am Main 2020", "date":"10/2019", "type":"Speech", "authors":"Körppen, T.", "img":"speech_ddo.jpeg", "abstract": "This presentation dealt with the importance of data and why companies (especially SMEs) need to use it as efficiently as possible. It showed how companies can determine their own level of analytics maturity and how companies with a low level of maturity can take a big step in the right direction cost-effectively by integrating a cross-company BI system."},
            {"id": 11, "title": "Smart logistics through ERP systems and IoT (german)", "outlet": "ERP Kongress Frankfurt am Main 2020", "date":"10/2019", "type":"Speech", "authors":"Körppen, T.", "img":"speech_iot.jpeg", "abstract": "This presentation outlined current challenges and opportunities of smart logistics and discussed how current trends and developments will influence the relationship with ERP systems. In addition, the audience could learn how IoT and ERP systems interact and how this symbiosis can support the transformation of logistics."},
            {"id": 12, "title": "Finding your way through the ERP jungle - How to make an informed selection decision (german)", "outlet": "ERP Kongress Frankfurt am Main 2021", "date":"10/2021", "type":"Speech", "authors":"Körppen, T.", "img":"speech_selection.jpeg", "abstract": "ERP systems are very complex and important for the operations of companies. Therefore, enormous costs are called for these and consumed for the operation. This presentation dealt with how a correct selection of a suitable ERP system must be carried out in order to maximize the selection security, i.e. to find a system that exactly fits one's own requirements. for this purpose, an overview of the market was also given and it was explained which pitfalls are to be considered during the selection."},
            {"id": 13, "title": "Intelligent ERP - How to determine the AI maturity of your system (german, main stage)", "outlet": "ERP Kongress Frankfurt am Main 2021", "date":"10/2021", "type":"Speech", "authors":"Körppen, T.", "img":"speech_ki.jpeg", "abstract": "This presentation addressed why ERP systems will be more dependent on AI in the future and in which areas of the system its use could be beneficial. In addition, it was shown which methodology an ERP provider or ERP user can use to recognize how intelligent their own ERP system is and in which areas the use of AI could be useful in the future to increase this intelligence."},
            {"id": 14, "title": "Data Science Governance - Key to Successful Value Creation through Data Products (german)", "outlet": "Bitkom AK Big Data & Advanced Analytics", "date":"6/2022", "type":"Speech", "authors":"Körppen, T., Euler, C.", "img":"speech_ds_bitkom.jpeg", "abstract": "In this presentation, Dr. Christoph Euler and I talked about the problems that can occur in the lifecycle of data science products. We also refreshed what data governance entails and which components need to be added to it in order to solve the problems in the live cycle of data science products. Finally, this data science governance was explained in several case studies."}
        ],
        "consulting": [
            {"id": 1, "info": {"year": "2022", "duration": "3 months", "role": "Consultant"}, "title": "Concept for customer data strategy", "client": {"industry": "Automotive", "revenue":"5bn"}, "img": "process.png", "description": "A comprehensive strategy paper was developed to help the customer accelerate the value-driven use of its customer data. This included, among other things, conducting maturity assessments, use case-driven value proposition identification, and creating concepts for data and technology management, governance, as well as tactical and strategic roadmaps and milestones."},
            {"id": 2, "info": {"year": "2022", "duration": "2 months", "role": "Consultant"}, "title": "Business case & strategy for analytics product", "client": {"industry": "Financial", "revenue":"150bn"}, "img": "software.png", "description": "The AI and IT department of the large corporation planned to roll out a new analytics & data product across the group and needed knowledge about costs and benefits as well as strategic support in positioning the product and guidance for planning the next steps and measures. For this purpose, business cases were calculated, demand was surveyed, positioning and communication concepts as well as roadmaps were created. Concepts for collaboration (for product creation and maintenance), roll-out and value harvesting were also developed."},
            {"id": 3, "info": {"year": "2021", "duration": "6 months", "role": "Sub-projectmanagement"}, "title": "Company-wide process consolidation & optimization", "client": {"industry": "Manufacturing/Automotive", "revenue":"250mn"}, "img": "analytics.png", "description": "In the past, the globally active company had little overview of its own processes and had corresponding disadvantages in terms of compliance testing, training, documentation, etc.. In the first step, a process map was created on the basis of which the most important core processes were represented and linked with each other. In the second step, potential analyses were carried out to streamline the processes, standardize them (between the subsidiaries) and accelerate them with the help of planned restructurings of the IT landscape."},
            {"id": 4, "info": {"year": "2021", "duration": "5 months", "role": "Consultant"}, "title": "Analytics cloud strategy", "client": {"industry": "Manufacturing/Automotive", "revenue":"250mn"}, "img": "process.png", "description": "Since the customer has various evaluation tools for analyzing their data (e.g. BI system, SQL, code, Excel), which often access the source systems themselves, an efficient connection and use was hardly possible. In order to simplify this process in the future and to be able to use additional data sources (alongside business data, production data in particular), a concept was developed for organizing data in cloud-based data lakes, data warehouses and data marts and making it available for analysis. This included the collection of requirements and their translation into technical and organizational concepts, including the pre-selection of suitable system components as well as catalogs of measures and roadmaps for the next steps."},
            {"id": 5, "info": {"year": "2020", "duration": "5 months", "role": "Consultant"}, "title": "Requirement assessment & ERP selection", "client": {"industry": "Multi-channel retail", "revenue":"300mn"}, "img": "analytics.png", "description": "Since the outdated, monolithic ERP system could no longer cope with current requirements, a new ERP system was to be selected. For this purpose, requirements were collected, alternatives evaluated and compared on the basis of selected criteria. In the course of the ERP selection, the entire IT landscape was evaluated and restructured according to the best-of-the-breed strategy. The question of cloud or on-premise was also discussed and evaluated on a customer-specific basis."},
            {"id": 6, "info": {"year": "2020", "duration": "4 months", "role": "Consultant"}, "title": "Analytics data strategy & business intelligence concept", "client": {"industry": "Multi-channel retail", "revenue":"300mn"}, "img": "process.png", "description": "Despite the considerable size and reach of the customer, reporting has in the past been primarily handled using various excel tools, SQL and rudimentary ERP functions. In order to increase efficiency, create transparency and make more targeted use of the customer's own data, a strategy was developed to raise the customer's analytics maturity. This included the identification of requirements and the selection of suitable technical foundations as well as definition of associated organizational concepts."},
            {"id": 7, "info": {"year": "2020", "duration": "4 months", "role": "Analyst"}, "title": "Concept for production restructuring ", "client": {"industry": "Manufacturing/Retail", "revenue":"150mn"}, "img": "analytics.png", "description": "In the past, the customer produced in workshop production (a product is produced in one place by one person) and reached the capacity limits of this model due to rapid growth. In order to achieve significant efficiency advantages, a concept was developed that would allow the introduction of serial production and thus enable more parallel and efficient production without having to sacrifice customer-specific individualization. For this purpose, analyses and simulations were carried out for the product range and a prototype of a clocked line assembly system was created."},
            {"id": 8, "info": {"year": "2019", "duration": "5 months", "role": "Analyst"}, "title": "Master data management strategy & governance concept", "client": {"industry": "Manufacturing/Retail", "revenue":"150mn"}, "img": "software.png", "description": "The data stored in the customer's existing system landscape was subjected to a quality assessment which revealed strong weaknesses in various dimensions. This motivated the creation of a strategy to achieve a significant improvement in data quality in the future. In addition, a governance concept (in particular with regard to responsibilities and organization) was created to ensure sustainable adherence to high quality standards and to guarantee reliable use of the data in the future."}
        ]
    },
    "other": {
        "logos": {
            "node.js": "https://upload.wikimedia.org/wikipedia/commons/d/d9/Node.js_logo.svg",
            "react.js": "https://upload.wikimedia.org/wikipedia/commons/a/a7/React-icon.svg",
            "express": "https://upload.wikimedia.org/wikipedia/commons/6/64/Expressjs.png",
            "django": "https://upload.wikimedia.org/wikipedia/commons/7/75/Django_logo.svg",
            "mongodb": "https://upload.wikimedia.org/wikipedia/commons/9/93/MongoDB_Logo.svg",
            "python": "https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg",
            "c#": "https://upload.wikimedia.org/wikipedia/commons/4/4f/Csharp_Logo.png",
            "java": "https://upload.wikimedia.org/wikipedia/de/e/e1/Java-Logo.svg",
            "javascript": "https://upload.wikimedia.org/wikipedia/commons/9/99/Unofficial_JavaScript_logo_2.svg",
            "solidity": "https://upload.wikimedia.org/wikipedia/commons/9/98/Solidity_logo.svg",
            "vuforia": "https://docs.unity3d.com/2017.2/Documentation/uploads/Main/vuforia_logo.png",
            "unity3d": "https://upload.wikimedia.org/wikipedia/commons/1/19/Unity_Technologies_logo.svg",
            "numpy":"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/2880px-NumPy_logo_2020.svg.png",
            "pandas":"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/2880px-Pandas_logo.svg.png",
            "matplotlib":"https://matplotlib.org/3.1.1/_static/logo2_compressed.svg",
            "pyqt":"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Python_and_Qt.svg/1920px-Python_and_Qt.svg.png",
            "scikit-learn":"https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg",
            "tensorflow":"https://www.gstatic.com/devrel-devsite/prod/vaa3422febae2287bcd4c6469032c7425ab2e6def56185b000bf112cadd0fbfd4/tensorflow/images/lockup.svg",
            "selenium":"https://upload.wikimedia.org/wikipedia/commons/9/9f/Selenium_logo.svg",
            "jquery":"https://upload.wikimedia.org/wikipedia/commons/f/fd/JQuery-Logo.svg",
            "ajax":"https://upload.wikimedia.org/wikipedia/commons/a/a1/AJAX_logo_by_gengns.svg",
            "openzeppelin":"https://www.openzeppelin.com/hs-fs/hubfs/OZ_logo_color%20(3)-1.png?width=600&name=OZ_logo_color%20(3)-1.png",
            "truffle":"https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_170,w_170,f_auto,b_white,q_auto:eco,dpr_1/gc5jbepkm8xpdk0nns0w",
            "ganache":"https://trufflesuite.com/img/ganache-logo-dark.svg",
            "infura":"https://lh3.googleusercontent.com/WMQvBalNhe7SqLHj_kRkxBh6JQA3EjL1M7S5t8B0qe9MEPFCAxyQqVD30QQ4tHeePzsb3AO7RFlVF84oBBhxjItjm7NYz_XHvnCxRfHfkxXnnieGUf5ROszWL_sogpENnVxQ_l0",
            "github-pages":"https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/collections/github-pages-examples/github-pages-examples.png",
            "azure":"https://upload.wikimedia.org/wikipedia/commons/a/a8/Microsoft_Azure_Logo.svg",
            "bootstrap":"https://upload.wikimedia.org/wikipedia/commons/b/b2/Bootstrap_logo.svg",
            "sqlite":"https://upload.wikimedia.org/wikipedia/commons/3/38/SQLite370.svg",
            "maven":"https://upload.wikimedia.org/wikipedia/commons/5/52/Apache_Maven_logo.svg",
            "redux":"https://upload.wikimedia.org/wikipedia/commons/4/49/Redux.png",
            "spring boot":"https://upload.wikimedia.org/wikipedia/commons/4/44/Spring_Framework_Logo_2018.svg",
            "linkedin": "https://upload.wikimedia.org/wikipedia/commons/0/01/LinkedIn_Logo.svg",
            "researchgate": "https://upload.wikimedia.org/wikipedia/commons/a/aa/ResearchGate_Logo.png",
            "github": "https://upload.wikimedia.org/wikipedia/commons/2/29/GitHub_logo_2013.svg",
            "e-mail": "https://upload.wikimedia.org/wikipedia/commons/7/7a/If_aiga_mail_134146_%281%29.png",
            "pytorch": "https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png",
            "colab": "https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg"
        },
        "imprint":"Information according to § 5 TMG\nTim Körppen\nContact\nE-mail: ws.tim.krpn@gmail.com"
    }
}